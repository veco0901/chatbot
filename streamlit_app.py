import streamlit as st
import chromadb
from chromadb import EphemeralClient
client = EphemeralClient()  # ë©”ëª¨ë¦¬ ì „ìš©
from llama_index.core import (
    VectorStoreIndex,
    SimpleDirectoryReader,
    StorageContext,
    SimpleKeywordTableIndex,
    TreeIndex,
    Settings
)
from llama_index.vector_stores.chroma import ChromaVectorStore
from IPython.display import Markdown, display
from clova_llama_index import ClovaClient, ClovaIndexEmbeddings, ClovaLLM

# --- UI ì„¤ì • ---
st.title("ğŸ’¬ ê³µê³µì¡°ë‹¬ ìƒë‹´ì‚¬")
st.write(
    """
    ê³µê³µì¡°ë‹¬, ì–´ë µê²Œë§Œ ëŠê»´ì§€ì…¨ë‚˜ìš”? \n
    ì´ ì±—ë´‡ì€ ì¤‘ì†Œê¸°ì—…, ë²¤ì²˜ê¸°ì—…, ê·¸ë¦¬ê³  í˜ì‹ ê¸°ì—… ì—¬ëŸ¬ë¶„ì´ ì¡°ë‹¬ ì‹œì¥ì— ì‰½ê²Œ ë‹¤ê°€ê°ˆ ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ëŠ” ë“ ë“ í•œ ê°€ì´ë“œì…ë‹ˆë‹¤. \n
    ì…ì°° ì ˆì°¨ë¶€í„° ì§€ì› ì œë„ê¹Œì§€, í•„ìš”í•œ ì •ë³´ë¥¼ ì‰½ê³  ë¹ ë¥´ê²Œ ì•Œë ¤ë“œë¦´ê²Œìš”.\n"""
)

# --- í´ë¡œë°” API ì„¤ì • ---
client = ClovaClient(api_key="nv-c4042ebc0d004d3a8bca5b8a27c39261bDcZ")
llm = ClovaLLM(client)
embed_model = ClovaIndexEmbeddings(client, embed_batch_size=1)
Settings.llm = llm
Settings.embed_model = embed_model
Settings.chunk_size = 1024

# --- ì¸ë±ì‹± ìºì‹± í•¨ìˆ˜ ---
from llama_index.core.tools import QueryEngineTool
from llama_index.core import VectorStoreIndex
from llama_index.core.objects import ObjectIndex
from llama_index.core.query_engine import ToolRetrieverRouterQueryEngine

@st.cache_resource(show_spinner="í…ŒìŠ¤íŠ¸ ë¬¸ì„œë¥¼ ì¸ë±ìŠ¤ í•˜ëŠ” ì¤‘...")
def load_query_engine():
    documents = SimpleDirectoryReader("/workspaces/chatbot/testdata").load_data()
    nodes = Settings.node_parser.get_nodes_from_documents(documents)

    storage_context = StorageContext.from_defaults()
    storage_context.docstore.add_documents(nodes)

    vector_index = VectorStoreIndex(nodes, storage_context=storage_context)
    keyword_index = SimpleKeywordTableIndex(nodes, storage_context=storage_context)
    tree_index = TreeIndex(nodes, storage_context=storage_context)

    vector_tool = QueryEngineTool.from_defaults(
        query_engine=vector_index.as_query_engine(response_mode="tree_summarize", use_async=True),
        name="vector",
        description="ì§€ì • ë°ì´í„°ì˜ íŠ¹ì • ë¶€ë¶„ì„ ê²€ìƒ‰í•  ë•Œ ìœ ìš©"
    )
    keyword_tool = QueryEngineTool.from_defaults(
        query_engine=keyword_index.as_query_engine(response_mode="tree_summarize", use_async=True),
        name="keyword",
        description="í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ì— ìœ ìš©"
    )
    tree_tool = QueryEngineTool.from_defaults(
        query_engine=tree_index.as_query_engine(response_mode="tree_summarize", use_async=True),
        name="tree",
        description="ì „ì²´ ë°ì´í„° í˜‘ì„±ê³¼ êµ¬ì¡° ì´í•´ì— ìœ ìš©"
    )

    obj_index = ObjectIndex.from_objects(
        [vector_tool, keyword_tool, tree_tool],
        index_cls=VectorStoreIndex,
    )
    return ToolRetrieverRouterQueryEngine(obj_index.as_retriever())

# --- ì¿¼ë¦¬ ì—”ì§„ ë¶ˆëŸ¬ì˜¤ê¸° ---
query_engine = load_query_engine()

# --- ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- ì´ì „ ë©”ì‹œì§€ í‘œì‹œ ---
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ ---
if prompt := st.chat_input("ê¶ê¸ˆí•œ ë‚´ìš©ì„ ì…ë ¥í•´ ì£¼ì„¸ìš”"):
    st.session_state.messages.append({
        "role": "user", 
        "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    response = query_engine.query(
        """
            ì•„ë˜ ì§ˆë¬¸ì— ëŒ€í•´ì„œ contextë¥¼ ì¶©ë¶„íˆ ê³ ë ¤í•´ì„œ
            í•­ìƒ í•œêµ­ë§ë¡œ ëŒ€ë‹µí•´ì¤˜
            {prompt}
        """)

    with st.chat_message("assistant"):
        st.markdown(response.response)

        st.session_state.messages.append({
            "role": "assistant",
            "content": response.response
        })
